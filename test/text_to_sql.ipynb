{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd0bca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os, holidays\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai # This will still work for now, but we'll adapt for the new library\n",
    "from datetime import datetime\n",
    "import json\n",
    "from prophet import Prophet # Import Prophet\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"API_KEY_GM\"))\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "conn = sqlite3.connect(\"bank_transactions.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b53bf5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_string(cursor):\n",
    "    \"\"\"\n",
    "    Retrieves the schema of all tables in the SQLite database.\n",
    "    \"\"\"\n",
    "    tables_info = []\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = [t[0] for t in cursor.fetchall()]\n",
    "\n",
    "    for table in tables:\n",
    "        cursor.execute(f\"PRAGMA table_info({table})\")\n",
    "        columns = cursor.fetchall()\n",
    "        col_defs = \", \".join([f\"{col[1]} {col[2]}\" for col in columns])\n",
    "        tables_info.append(f\"{table}({col_defs})\")\n",
    "\n",
    "    return \"\\n\".join(tables_info)\n",
    "\n",
    "schema = get_schema_string(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359251ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_philippine_holidays():\n",
    "    \"\"\"\n",
    "    Returns a list of significant Philippine holidays for the current and next year\n",
    "    using the 'holidays' library.\n",
    "    \"\"\"\n",
    "    today = datetime.now()\n",
    "    current_year = today.year\n",
    "    next_year = today.year + 1\n",
    "\n",
    "    ph_holidays = holidays.PH(years=[current_year, next_year])\n",
    "\n",
    "    holiday_list = []\n",
    "    for date, name in sorted(ph_holidays.items()):\n",
    "        # Format the date nicely for the prompt, e.g., \"January 1\"\n",
    "        formatted_date = date.strftime('%B %d')\n",
    "        holiday_list.append(f\"{formatted_date}: {name}\")\n",
    "\n",
    "    return holiday_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "712a3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_banking_assistant_prompt(schema, conversation_history=None, query_results_with_headers=None):\n",
    "    \"\"\"\n",
    "    Generates the core prompt for the banking assistant, including the schema, guidelines,\n",
    "    and optionally conversation history, query results with headers, and Philippine holidays.\n",
    "    \"\"\"\n",
    "    ph_holidays = get_philippine_holidays()\n",
    "    holidays_str = \"\\n\".join([f\"- {h}\" for h in ph_holidays])\n",
    "\n",
    "    prompt_parts = [f\"\"\"\n",
    "You are a friendly and intelligent banking assistant that helps users understand their financial activity by translating questions into SQL and providing clear, conversational answers — similar to how you'd reply in a chat or web interface like Gemini.\n",
    "\n",
    "Your expertise is with BDO accounts, and you're familiar with Philippine banking habits, cities (including acronyms like QC, MKT, etc.), and common transaction types (e.g., service charges, deposits, ATM withdrawals).\n",
    "\n",
    "Database schema:\n",
    "{schema}\n",
    "\n",
    "Current Date: {datetime.now().strftime('%B %d, %Y')}\n",
    "\n",
    "Philippine Holidays (for context, not for SQL queries unless explicitly asked about transactions on these dates):\n",
    "{holidays_str}\n",
    "\n",
    "Guidelines for SQL generation:\n",
    "- For each user question, arrange the date in ascending order.\n",
    "- When summing amounts like Deposits or Withdrawals, always use COALESCE(column, 0) to treat NULL as zero.\n",
    "- Quote column names with spaces or special characters (e.g., \"Branch / Source\") in SQL.\n",
    "- For counts or comparisons, write WHERE conditions as needed (e.g., Balance < 30000).\n",
    "- For service charges, match using Transaction Details like '%service charge%'.\n",
    "- NULL balances should not be included in comparisons (treat as missing).\n",
    "- When a user asks about transactions during a holiday, try to identify the date(s) of that holiday from the provided list.\n",
    "\n",
    "When replying, first provide the SQL query, and then, using the results of that query, generate a friendly, conversational, and emotionally aware response. Do NOT include the SQL query in your final response to the user.\n",
    "\n",
    "Return your response as a Python dictionary with two keys:\n",
    "- \"sql\": The generated SQL query.\n",
    "- \"natural_language_response\": The friendly, conversational response generated by you, based on the query results.\n",
    "\n",
    "Important: The \"natural_language_response\" should be a complete, ready-to-display message. Directly incorporate the value from the SQL query results. For transaction details, always provide essential information like Date, Transaction Details, Branch, and the amount (Withdrawal or Deposit).\n",
    "\n",
    "Example:\n",
    "\n",
    "User: How much did I spend on service charges?\n",
    "\n",
    "Response:\n",
    "{{\n",
    "  \"sql\": \"SELECT SUM(COALESCE(Withdrawals, 0)) FROM bank_transactions WHERE LOWER(\\\"Transaction Details\\\") LIKE '%service charge%';\",\n",
    "  \"natural_language_response\": \"You've spent a total of ₱500.00 on service charges. Is there anything else you'd like to check about your expenses?\"\n",
    "}}\n",
    "\n",
    "Your responses should sound warm, conversational, and emotionally aware — like a smart banking assistant (e.g., Bank of America’s Erica, Axis Aha!).\n",
    "Use casual phrasing where appropriate. Add context or questions to prompt further conversation (e.g., 'Want help reviewing this?', 'Let me know if that looks off!').\n",
    "Avoid sounding robotic or too technical. Avoid repeating the user's question.\n",
    "Be brief, helpful, and brand-friendly.\n",
    "\"\"\"]\n",
    "\n",
    "    if conversation_history:\n",
    "        prompt_parts.append(\"\\n--- Conversation History ---\")\n",
    "        for turn in conversation_history:\n",
    "            prompt_parts.append(f\"User: {turn['user']}\\nAssistant: {turn['assistant']}\")\n",
    "        prompt_parts.append(\"----------------------------\")\n",
    "\n",
    "    if query_results_with_headers:\n",
    "        # Prepare results for Gemini to understand contextually\n",
    "        headers = query_results_with_headers['headers']\n",
    "        rows = query_results_with_headers['rows']\n",
    "\n",
    "        # Format results to be easily parseable by Gemini\n",
    "        formatted_results = [headers]\n",
    "        for row in rows:\n",
    "            formatted_row = []\n",
    "            for item in row:\n",
    "                if isinstance(item, (int, float)):\n",
    "                    formatted_row.append(f\"{item:,.2f}\") # Format numbers for clarity\n",
    "                else:\n",
    "                    formatted_row.append(str(item))\n",
    "            formatted_results.append(formatted_row)\n",
    "\n",
    "        prompt_parts.append(f\"\\n--- SQL Query Results ---\")\n",
    "        prompt_parts.append(json.dumps(formatted_results, indent=2)) # Send as JSON for structured input\n",
    "        prompt_parts.append(\"-------------------------\")\n",
    "\n",
    "    return \"\\n\".join(prompt_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b09e5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(user_question, model, schema_prompt_func, conversation_history=None, query_results_with_headers=None):\n",
    "    \"\"\"\n",
    "    Sends the user's question, conversation history, and optionally query results with headers\n",
    "    to the Gemini model and returns the parsed JSON response.\n",
    "    \"\"\"\n",
    "    # Generate the prompt dynamically based on the current state (conversation history, results)\n",
    "    full_prompt = f\"{schema_prompt_func(schema, conversation_history, query_results_with_headers)}\\n\\nUser: {user_question}\\n\\nAssistant Response:\"\n",
    "\n",
    "    gemini_response = model.generate_content(full_prompt)\n",
    "    content = gemini_response.text.strip()\n",
    "\n",
    "    # Robust parsing for the JSON string\n",
    "    if content.startswith(\"```json\"):\n",
    "        json_str = content.strip().split('\\n', 1)[1].rsplit('```', 1)[0]\n",
    "    elif content.startswith(\"```\"):\n",
    "        json_str = content.strip().split('\\n', 1)[1].rsplit('```', 1)[0]\n",
    "    else:\n",
    "        json_str = content\n",
    "\n",
    "    try:\n",
    "        response_dict = json.loads(json_str)\n",
    "        return response_dict\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from Gemini: {e}\")\n",
    "        print(f\"Raw Gemini response: {content}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1500136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I'm your friendly BDO banking assistant. How can I help you today?\n",
      "You can ask me things like 'How much did I spend last month?' or 'Show me my recent deposits.'\n",
      "Type 'exit' or 'goodbye' to end our chat.\n",
      "Assistant: Thinking...\n",
      "Assistant: Hello! How can I help you today?\n",
      "Assistant: Thanks for chatting! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "def chat_with_banking_assistant():\n",
    "    \"\"\"\n",
    "    Starts an interactive chat with the banking assistant, with Gemini generating the full response.\n",
    "    Includes context management and graceful exit.\n",
    "    \"\"\"\n",
    "    conversation_history = [] # Stores (user_question, assistant_response) tuples\n",
    "\n",
    "    print(\"Hi there! I'm your friendly BDO banking assistant. How can I help you today?\")\n",
    "    print(\"You can ask me things like 'How much did I spend last month?' or 'Show me my recent deposits.'\")\n",
    "    print(\"Type 'exit' or 'goodbye' to end our chat.\")\n",
    "\n",
    "    exit_phrases = [\"exit\", \"goodbye\", \"thank you\", \"thanks\", \"thats all\", \"that's all\"]\n",
    "\n",
    "    while True:\n",
    "        user_question = input(\"\\nMe: \").strip()\n",
    "\n",
    "        if any(phrase in user_question.lower() for phrase in exit_phrases):\n",
    "            print(\"Assistant: Thanks for chatting! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        print(\"Assistant: Thinking...\")\n",
    "\n",
    "        # Step 1: Get SQL query from Gemini (passing history for context)\n",
    "        # We pass get_banking_assistant_prompt as a function reference\n",
    "        response_for_sql = get_gemini_response(user_question, model, get_banking_assistant_prompt, conversation_history=conversation_history)\n",
    "\n",
    "        if not response_for_sql or \"sql\" not in response_for_sql:\n",
    "            print(\"Assistant: I'm sorry, I couldn't generate a SQL query for that request. Could you please rephrase it?\")\n",
    "            # Add this turn to history if desired, even if it's an error\n",
    "            conversation_history.append({\"user\": user_question, \"assistant\": \"I'm sorry, I couldn't generate a SQL query for that request.\"})\n",
    "            continue\n",
    "\n",
    "        sql_query = response_for_sql[\"sql\"]\n",
    "\n",
    "        try:\n",
    "            cursor.execute(sql_query)\n",
    "            query_results = cursor.fetchall()\n",
    "\n",
    "            # Get column names from cursor description for better context\n",
    "            column_headers = [description[0] for description in cursor.description]\n",
    "            query_results_with_headers = {\"headers\": column_headers, \"rows\": query_results}\n",
    "\n",
    "            # Step 2: Send SQL query results back to Gemini for natural language generation\n",
    "            # Pass user_question, conversation_history, and the structured query_results_with_headers\n",
    "            final_response_dict = get_gemini_response(\n",
    "                user_question, model, get_banking_assistant_prompt,\n",
    "                conversation_history=conversation_history,\n",
    "                query_results_with_headers=query_results_with_headers\n",
    "            )\n",
    "\n",
    "            if final_response_dict and \"natural_language_response\" in final_response_dict:\n",
    "                assistant_response_text = final_response_dict['natural_language_response']\n",
    "                print(f\"Assistant: {assistant_response_text}\")\n",
    "                # Add successful turn to conversation history\n",
    "                conversation_history.append({\"user\": user_question, \"assistant\": assistant_response_text})\n",
    "            else:\n",
    "                print(\"Assistant: I executed the query, but I had trouble forming a clear response. Please try again.\")\n",
    "                conversation_history.append({\"user\": user_question, \"assistant\": \"I executed the query, but I had trouble forming a clear response.\"})\n",
    "\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Assistant: I ran into an issue processing that request. Database error: {e}\")\n",
    "            print(\"Assistant: Could you try rephrasing your question?\")\n",
    "            conversation_history.append({\"user\": user_question, \"assistant\": f\"I ran into an issue: {e}\"})\n",
    "        except Exception as e:\n",
    "            print(f\"Assistant: An unexpected error occurred: {e}\")\n",
    "            print(\"Assistant: Please try again or rephrase your question.\")\n",
    "            conversation_history.append({\"user\": user_question, \"assistant\": f\"An unexpected error occurred: {e}\"})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_banking_assistant()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.utilities import SQLDatabase\n",
    "# from langchain_community.agent_toolkits import create_sql_agent\n",
    "# from langchain.agents.agent_types import AgentType\n",
    "# from langchain_google_genai import GoogleGenerativeAI\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# g_api_key = os.getenv(\"GOOGLE_API_KEY\") or 'AIzaSyBbTlx6tf8U5eMqKb5o87uajhTROQvFSEQ'\n",
    "\n",
    "# # Replace with your actual database URL\n",
    "# # For example, for PostgreSQL: \"postgresql+psycopg2://user:password@localhost/dbname\"\n",
    "# # For MySQL: \"mysql+pymysql://user:password@localhost/dbname\"\n",
    "# db = SQLDatabase.from_uri(\"sqlite:///bank_data.db\")  # Example using SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = GoogleGenerativeAI(\n",
    "#     model=\"models/text-bison-001\",  # Text-to-SQL needs reasoning ability\n",
    "#     google_api_key=g_api_key,\n",
    "#     temperature=0  # Reduce hallucinations\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor = create_sql_agent(\n",
    "#     llm=llm,\n",
    "#     db=db,\n",
    "#     agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#     verbose=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b922049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Which accounts made transactions over 100,000 pesos in May 2024?\"\n",
    "# response = agent_executor.invoke({\"input\": query})\n",
    "# print(response)  # Correct way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eccc0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are your 5 most recent transactions, starting with the latest:\n",
      "\n",
      "On 2025-05-15 00:00:00, you deposited ₱21,109.85 at BDO Online for “Deposit: Salary”. On 2025-05-15 00:00:00, you deposited ₱14,891.36 at BDO Cebu for “Deposit: Salary”. On 2025-05-15 00:00:00, you withdrew ₱53.64 at BDO Cebu for “Service Charge”. On 2025-05-14 00:00:00, you deposited ₱2,019.04 at BDO Davao for “Interest Credit”. On 2025-05-13 00:00:00, you withdrew ₱7,002.25 at BDO Online for “POS Purchase”.\n"
     ]
    }
   ],
   "source": [
    "# import sqlite3\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# import google.generativeai as genai\n",
    "# import json\n",
    "\n",
    "# load_dotenv()\n",
    "# genai.configure(api_key=os.getenv(\"API_KEY_GM\"))\n",
    "# model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# conn = sqlite3.connect(\"bank_transactions.db\")\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# def get_schema_string(cursor):\n",
    "#     tables_info = []\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#     tables = [t[0] for t in cursor.fetchall()]\n",
    "    \n",
    "#     for table in tables:\n",
    "#         cursor.execute(f\"PRAGMA table_info({table})\")\n",
    "#         columns = cursor.fetchall()\n",
    "#         col_defs = \", \".join([f\"{col[1]} {col[2]}\" for col in columns])\n",
    "#         tables_info.append(f\"{table}({col_defs})\")\n",
    "    \n",
    "#     return \"\\n\".join(tables_info)\n",
    "\n",
    "# schema = get_schema_string(cursor)\n",
    "\n",
    "# user_question = \"Show my last 5 transactions\"\n",
    "\n",
    "# schema_prompt = f\"\"\"\n",
    "# You are a friendly and intelligent banking assistant that helps users understand their financial activity by translating questions into SQL and returning clear, conversational answers — similar to how you'd reply in a chat or web interface like Gemini.\n",
    "\n",
    "# Your expertise is with BDO accounts, and you're familiar with Philippine banking habits, cities (including acronyms like QC, MKT, etc.), and common transaction types (e.g., service charges, deposits, ATM withdrawals).\n",
    "\n",
    "# Database schema:\n",
    "# bank_transactions(\n",
    "#     Date TEXT,  -- format: MM/DD/YYYY\n",
    "#     \"Transaction Details\" TEXT,\n",
    "#     \"Branch / Source\" TEXT,\n",
    "#     Withdrawals NUMERIC,\n",
    "#     Deposits NUMERIC,\n",
    "#     Balance NUMERIC\n",
    "# )\n",
    "\n",
    "# Guidelines:\n",
    "# - For each user question, arrange the date in ascending order.\n",
    "# - When summing amounts like Deposits or Withdrawals, always use COALESCE(column, 0) to treat NULL as zero.\n",
    "# - Quote column names with spaces or special characters (e.g., \"Branch / Source\") in SQL.\n",
    "# - For counts or comparisons, write WHERE conditions as needed (e.g., Balance < 30000).\n",
    "# - For service charges, match using Transaction Details like '%service charge%'.\n",
    "# - NULL balances should not be included in comparisons (treat as missing).\n",
    "# - Never include SQL in your reply to the user.\n",
    "\n",
    "# When replying, return only a Python dictionary like this:\n",
    "\n",
    "# {{\n",
    "#   \"sql\": \"...\",\n",
    "#   \"response_template\": \"Your friendly response here, with {{result}} inserted where the result will appear.\"\n",
    "# }}\n",
    "\n",
    "# Example:\n",
    "\n",
    "# User: How much did I spend on service charges?\n",
    "\n",
    "# Response:\n",
    "# {{\n",
    "#   \"sql\": \"SELECT SUM(COALESCE(Withdrawals, 0)) FROM bank_transactions WHERE LOWER(\\\"Transaction Details\\\") LIKE '%service charge%';\",\n",
    "#   \"response_template\": \"You’ve spent a total of ₱{{result}} on service charges.\"\n",
    "# }}\n",
    "\n",
    "# Always aim to sound natural, helpful, and concise — just like in a conversational app.\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = f\"{schema_prompt}\\n\\nUser: {user_question}\"\n",
    "\n",
    "# gemini_response = model.generate_content(prompt)\n",
    "# content = gemini_response.text.strip()\n",
    "\n",
    "# if content.startswith(\"```\"):\n",
    "#     json_str = content.strip().split('\\n', 1)[1].rsplit('```', 1)[0]\n",
    "# else:\n",
    "#     json_str = content\n",
    "\n",
    "# response_dict = json.loads(json_str)\n",
    "\n",
    "# cursor.execute(response_dict['sql'])\n",
    "\n",
    "# query_results = cursor.fetchall()\n",
    "\n",
    "# # Format results into conversational string\n",
    "# if query_results:\n",
    "#     if len(query_results[0]) == 1 and len(query_results) == 1:\n",
    "#         # Single numeric result (like balance)\n",
    "#         formatted_results = f\"{query_results[0][0]:,.2f}\"\n",
    "#     else:\n",
    "#         # Turn first 3 transactions into a conversational paragraph\n",
    "#         transaction_descriptions = []\n",
    "#         for row in query_results:\n",
    "#             date, details, branch, w, d, bal = row\n",
    "#             action = \"\"\n",
    "#             if w and w > 0:\n",
    "#                 action = f\"withdrew ₱{w:,.2f}\"\n",
    "#             elif d and d > 0:\n",
    "#                 action = f\"deposited ₱{d:,.2f}\"\n",
    "#             else:\n",
    "#                 action = \"had a transaction\"\n",
    "\n",
    "#             description = f\"On {date}, you {action} at {branch} for “{details}”.\"\n",
    "#             transaction_descriptions.append(description)\n",
    "\n",
    "#         formatted_results = \" \".join(transaction_descriptions)\n",
    "# else:\n",
    "#     formatted_results = \"I couldn’t find any transactions after that date.\"\n",
    "\n",
    "\n",
    "# # Fill the friendly response template with formatted results\n",
    "# final_response = response_dict['response_template'].format(result=formatted_results)\n",
    "\n",
    "# print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3883bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total service charges: 25356.1\n"
     ]
    }
   ],
   "source": [
    "# query = \"\"\"SELECT SUM(COALESCE(Withdrawals, 0)) AS total_service_charges\n",
    "# FROM bank_transactions\n",
    "# WHERE LOWER(\"Transaction Details\") LIKE '%service charge%';\n",
    "# \"\"\"\n",
    "\n",
    "# cursor.execute(query)\n",
    "\n",
    "# query_results = cursor.fetchall()\n",
    "\n",
    "# if query_results:\n",
    "# \ttotal_service_charges = query_results[0][0]\n",
    "# \tprint(f\"Total service charges: {total_service_charges}\")\n",
    " \n",
    "# else:\n",
    "# \tprint(\"No service charges found in the transactions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guilherme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
